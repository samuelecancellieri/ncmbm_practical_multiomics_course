{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5fab73d3",
      "metadata": {},
      "source": [
        "# ATAC-seq Processing Pipeline - Student Exercise\n",
        "\n",
        "## Learning Objectives\n",
        "By completing this notebook, you will:\n",
        "- Understand the ATAC-seq data analysis workflow\n",
        "- Learn about chromatin accessibility analysis\n",
        "- Process paired-end ATAC-seq reads to identify open chromatin regions\n",
        "- Calculate important quality metrics (PBC1, PBC2, NRF, FRiP)\n",
        "\n",
        "## Pipeline Overview\n",
        "```\n",
        "Raw FASTQ ‚Üí Trimming ‚Üí Alignment ‚Üí Filter ‚Üí Mark Duplicates ‚Üí Peak Calling\n",
        "   (Input)  (Trim Galore) (Bowtie2)  (QC)    (Picard)        (MACS2)\n",
        "```\n",
        "\n",
        "## What is ATAC-seq?\n",
        "**ATAC-seq** (Assay for Transposase-Accessible Chromatin) identifies open chromatin regions where DNA is accessible for transcription factor binding.\n",
        "\n",
        "## Quality Metrics Explained\n",
        "- **PBC1** (PCR Bottlenecking Coefficient 1): Library complexity indicator\n",
        "- **PBC2** (PCR Bottlenecking Coefficient 2): Duplicate rate indicator  \n",
        "- **NRF** (Non-Redundant Fraction): Unique reads / Total reads\n",
        "- **FRiP** (Fraction of Reads in Peaks): Signal-to-noise ratio\n",
        "\n",
        "## Required Tools\n",
        "- **Trim Galore** (0.6.10): Adapter trimming\n",
        "- **Bowtie2** (2.4.1): Short read aligner\n",
        "- **Samtools** (1.7): BAM file processing\n",
        "- **Picard** (2.23.4): Duplicate marking\n",
        "- **MACS2** (2.2.7.1): Peak calling\n",
        "- **Bedtools** (2.29.2): Genomic interval operations\n",
        "- **deeptools** (3.5.5): Coverage and visualization\n",
        "\n",
        "---\n",
        "\n",
        "**Instructions**: Follow the cells below and complete sections marked with `# TODO`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23d6ceb4",
      "metadata": {},
      "source": [
        "## Step 1: Import Python Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d20950",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"‚úì Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f6aad9c",
      "metadata": {},
      "source": [
        "## Step 2: Define Bioinformatics Tool Containers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8429df26",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Container images for each tool\n",
        "trimgalore_container = \"quay.io/biocontainers/trim-galore:0.6.10--hdfd78af_1\"\n",
        "bowtie2_container = \"quay.io/biocontainers/bowtie2:2.4.1--py38h1c8e9b9_3\"\n",
        "samtools_container = \"quay.io/biocontainers/samtools:1.7--2\"\n",
        "picard_container = \"quay.io/biocontainers/picard:2.23.4--0\"\n",
        "macs2_container = \"quay.io/biocontainers/macs2:2.2.7.1--py39hbf8eff0_5\"\n",
        "bedtools_container = \"quay.io/biocontainers/bedtools:2.29.2--hc088bd4_0\"\n",
        "deeptools_container = \"quay.io/biocontainers/deeptools:3.5.5--pyhdfd78af_0\"\n",
        "\n",
        "print(\"‚úì Container images defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c420c581",
      "metadata": {},
      "source": [
        "## Step 3: Set Your Pipeline Parameters\n",
        "\n",
        "**üìù TODO: Update these paths with your actual data!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78d2dc64",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Update these paths to match your data location\n",
        "fastq1 = \"/path/to/your/sample_R1.fq.gz\"      # Forward reads\n",
        "fastq2 = \"/path/to/your/sample_R2.fq.gz\"      # Reverse reads\n",
        "basename = \"my_atac_sample\"                    # Sample name\n",
        "output_dir = \"/path/to/output_directory\"       # Where to save results\n",
        "\n",
        "# Reference genome files (ask your instructor for these paths)\n",
        "genome_index = \"/path/to/bowtie2_index\"        # Bowtie2 genome index\n",
        "genome_fasta = \"/path/to/genome.fasta\"         # Genome FASTA file\n",
        "\n",
        "# Reference data for quality control\n",
        "# TODO: Update these paths to your chromosome sizes and blacklist files\n",
        "CHROMSIZES = \"/path/to/hg38.chrom.sizes\"       # Chromosome sizes file\n",
        "BLACKLIST = \"/path/to/GRCh38_unified_blacklist.bed\"  # ENCODE blacklist regions\n",
        "\n",
        "# Analysis settings\n",
        "threads = 2                                     # Number of CPU threads\n",
        "# TODO: Update this to your accessible directory for Singularity\n",
        "BIND_DIR = \"/path/to/accessible_directory/\"    # Directory accessible to Singularity\n",
        "\n",
        "print(f\"Sample name: {basename}\")\n",
        "print(f\"Threads: {threads}\")\n",
        "print(\"‚ö† Remember to update the file paths above before running!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87f8bc01",
      "metadata": {},
      "source": [
        "## Step 4: Create Output Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d63b30b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directory structure\n",
        "OUTPUT_DIR = os.path.join(os.path.abspath(output_dir), f\"{basename}_results\")\n",
        "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Create subdirectories\n",
        "qc_dir = os.path.join(OUTPUT_DIR, f\"{basename}_qc\")\n",
        "picard_dir = os.path.join(OUTPUT_DIR, f\"{basename}_picard\")\n",
        "peaks_dir = os.path.join(OUTPUT_DIR, f\"{basename}_peaks\")\n",
        "\n",
        "for d in [qc_dir, picard_dir, peaks_dir]:\n",
        "    Path(d).mkdir(exist_ok=True)\n",
        "\n",
        "# Initialize log file\n",
        "log_file = os.path.join(OUTPUT_DIR, f\"{basename}_pipeline.log\")\n",
        "\n",
        "print(f\"‚úì Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"‚úì QC directory: {qc_dir}\")\n",
        "print(f\"‚úì Picard directory: {picard_dir}\")\n",
        "print(f\"‚úì Peaks directory: {peaks_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09c66ce6",
      "metadata": {},
      "source": [
        "## Step 5: Trim Adapters with Trim Galore\n",
        "\n",
        "**What does this do?** ATAC-seq uses a special hard trimming strategy (50bp from 5' end) to remove transposase sequences.\n",
        "\n",
        "**üìù TODO: Run this cell and observe the trimming output.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e78f1f65",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: Hard trimming to 50bp and adapter removal\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Step 1: Hard trim to 50bp from 5' end\n",
        "print(\"\\n[1/2] Hard trimming to 50bp...\")\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{trimgalore_container}\",\n",
        "    \"trim_galore\",\n",
        "    \"--paired\",\n",
        "    \"--hardtrim5\", \"50\",  # ATAC-seq specific: trim to 50bp\n",
        "    \"-j\", str(threads),\n",
        "    \"--basename\", basename,\n",
        "    \"-o\", OUTPUT_DIR,\n",
        "    fastq1, fastq2\n",
        "]\n",
        "\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"‚úì Hard trimming completed\")\n",
        "    # Rename output files for consistency\n",
        "    trimmed1 = os.path.join(OUTPUT_DIR, f\"{basename}_R1.50bp_5prime.fq.gz\")\n",
        "    trimmed2 = os.path.join(OUTPUT_DIR, f\"{basename}_R2.50bp_5prime.fq.gz\")\n",
        "else:\n",
        "    print(f\"‚úó Error: {result.stderr}\")\n",
        "\n",
        "# Step 2: Quality and adapter trimming\n",
        "print(\"\\n[2/2] Quality and adapter trimming...\")\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{trimgalore_container}\",\n",
        "    \"trim_galore\",\n",
        "    \"--paired\",\n",
        "    \"-j\", str(threads),\n",
        "    \"--basename\", basename,\n",
        "    \"-o\", OUTPUT_DIR,\n",
        "    trimmed1, trimmed2\n",
        "]\n",
        "\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"‚úì Adapter trimming completed!\")\n",
        "    fastq1_trimmed = os.path.join(OUTPUT_DIR, f\"{basename}_val_1.fq.gz\")\n",
        "    fastq2_trimmed = os.path.join(OUTPUT_DIR, f\"{basename}_val_2.fq.gz\")\n",
        "    print(f\"  Trimmed files ready for alignment\")\n",
        "else:\n",
        "    print(f\"‚úó Error: {result.stderr}\")\n",
        "    \n",
        "# Question: Why does ATAC-seq require hard trimming to 50bp?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9375cdd",
      "metadata": {},
      "source": [
        "## Step 6: Align Reads with Bowtie2\n",
        "\n",
        "**What does this do?** Maps reads to the reference genome using Bowtie2 (optimized for short reads).\n",
        "\n",
        "**üìù TODO: Complete the Bowtie2 command.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f320cff",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 2: Alignment with Bowtie2\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "fastq1_trimmed = os.path.join(OUTPUT_DIR, f\"{basename}_val_1.fq.gz\")\n",
        "fastq2_trimmed = os.path.join(OUTPUT_DIR, f\"{basename}_val_2.fq.gz\")\n",
        "sam_file = os.path.join(OUTPUT_DIR, f\"{basename}.sam\")\n",
        "\n",
        "# TODO: Fill in the correct container name\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{bowtie2_container}\",  # TODO: Which container?\n",
        "    \"bowtie2\",\n",
        "    \"--very-sensitive\",     # Use sensitive alignment mode\n",
        "    \"-p\", str(threads),\n",
        "    \"-x\", genome_index,     # Bowtie2 index\n",
        "    \"-1\", fastq1_trimmed,\n",
        "    \"-2\", fastq2_trimmed\n",
        "]\n",
        "\n",
        "print(\"Running Bowtie2 alignment (this may take several minutes)...\")\n",
        "with open(sam_file, 'w') as outfile:\n",
        "    result = subprocess.run(cmd, stdout=outfile, stderr=subprocess.PIPE, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"‚úì Alignment completed!\")\n",
        "    print(f\"  SAM file: {sam_file}\")\n",
        "    print(f\"\\nAlignment stats:\\n{result.stderr}\")\n",
        "else:\n",
        "    print(f\"‚úó Error: {result.stderr}\")\n",
        "    \n",
        "# Question: What does the overall alignment rate tell you about your data quality?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5872eb23",
      "metadata": {},
      "source": [
        "## Step 7: Filter Reads - Remove Mitochondrial and Unwanted Chromosomes\n",
        "\n",
        "**What does this do?** Removes reads from mitochondria (technical artifact) and keeps only main chromosomes.\n",
        "\n",
        "**üìù TODO: Complete the filtering steps.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c69816",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 3: Filter reads - remove chrM and unwanted chromosomes\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "sam_file = os.path.join(OUTPUT_DIR, f\"{basename}.sam\")\n",
        "bam_file = os.path.join(OUTPUT_DIR, f\"{basename}.bam\")\n",
        "sorted_bam = os.path.join(OUTPUT_DIR, f\"{basename}_sorted.bam\")\n",
        "filtered_bam = os.path.join(OUTPUT_DIR, f\"{basename}_filtered.bam\")\n",
        "\n",
        "# Keep only main chromosomes\n",
        "main_chromosomes = [\"chr1\", \"chr2\", \"chr3\", \"chr4\", \"chr5\", \"chr6\", \"chr7\", \n",
        "                   \"chr8\", \"chr9\", \"chr10\", \"chr11\", \"chr12\", \"chr13\", \"chr14\",\n",
        "                   \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\", \n",
        "                   \"chr21\", \"chr22\", \"chrX\"]\n",
        "\n",
        "print(\"[1/4] Converting SAM to BAM...\")\n",
        "# TODO: Complete the samtools view command\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{samtools_container}\",  # TODO: Which container?\n",
        "    \"samtools\", \"view\",\n",
        "    \"-h\", \"-@\", str(threads),\n",
        "    \"-O\", \"bam\",\n",
        "    \"-o\", bam_file,\n",
        "    sam_file\n",
        "]\n",
        "subprocess.run(cmd, capture_output=False)\n",
        "print(\"‚úì SAM to BAM conversion done\")\n",
        "\n",
        "print(\"[2/4] Sorting BAM file...\")\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{samtools_container}\",\n",
        "    \"samtools\", \"sort\",\n",
        "    \"-@\", str(threads),\n",
        "    \"-o\", sorted_bam,\n",
        "    bam_file\n",
        "]\n",
        "subprocess.run(cmd, capture_output=False)\n",
        "print(\"‚úì Sorting done\")\n",
        "\n",
        "print(\"[3/4] Indexing BAM file...\")\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{samtools_container}\",\n",
        "    \"samtools\", \"index\",\n",
        "    \"-@\", str(threads),\n",
        "    sorted_bam\n",
        "]\n",
        "subprocess.run(cmd, capture_output=False)\n",
        "print(\"‚úì Indexing done\")\n",
        "\n",
        "print(\"[4/4] Filtering chromosomes...\")\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{samtools_container}\",\n",
        "    \"samtools\", \"view\",\n",
        "    \"-h\", \"-@\", str(threads),\n",
        "    \"-O\", \"bam\",\n",
        "    \"-o\", filtered_bam,\n",
        "    sorted_bam\n",
        "] + main_chromosomes\n",
        "\n",
        "subprocess.run(cmd, capture_output=False)\n",
        "print(\"‚úì Chromosome filtering completed!\")\n",
        "\n",
        "# Question: Why do we remove mitochondrial reads in ATAC-seq?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2264d45",
      "metadata": {},
      "source": [
        "## Step 8: Calculate Mitochondrial Read Fraction (Quality Metric)\n",
        "\n",
        "**What does this do?** High mitochondrial fraction indicates poor quality ATAC-seq data.\n",
        "\n",
        "**Good ATAC-seq: <10% mitochondrial reads**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aa453da",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 4: Calculate mitochondrial read fraction\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "sorted_bam = os.path.join(OUTPUT_DIR, f\"{basename}_sorted.bam\")\n",
        "\n",
        "# Count total reads\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{samtools_container}\",\n",
        "    \"samtools\", \"view\", \"-c\", sorted_bam\n",
        "]\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "total_reads = int(result.stdout.strip())\n",
        "\n",
        "# Count chrM reads\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{samtools_container}\",\n",
        "    \"samtools\", \"view\", \"-c\", sorted_bam, \"chrM\"\n",
        "]\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "chrM_reads = int(result.stdout.strip())\n",
        "\n",
        "# Calculate fraction\n",
        "chrM_fraction = chrM_reads / total_reads if total_reads > 0 else 0\n",
        "chrM_percent = chrM_fraction * 100\n",
        "\n",
        "print(f\"\\nüìä Mitochondrial Read Statistics:\")\n",
        "print(f\"  Total reads: {total_reads:,}\")\n",
        "print(f\"  chrM reads: {chrM_reads:,}\")\n",
        "print(f\"  chrM fraction: {chrM_fraction:.4f} ({chrM_percent:.2f}%)\")\n",
        "\n",
        "if chrM_percent < 10:\n",
        "    print(\"  ‚úì PASS: Good quality (<10% chrM)\")\n",
        "elif chrM_percent < 20:\n",
        "    print(\"  ‚ö† WARNING: Moderate chrM content (10-20%)\")\n",
        "else:\n",
        "    print(\"  ‚úó FAIL: High chrM content (>20%) - consider sample quality\")\n",
        "\n",
        "# Save to file\n",
        "chrM_file = os.path.join(qc_dir, f\"{basename}_chrM_fraction.txt\")\n",
        "with open(chrM_file, 'w') as f:\n",
        "    f.write(\"chrM_reads\\tTotal_reads\\tchrM_fraction\\n\")\n",
        "    f.write(f\"{chrM_reads}\\t{total_reads}\\t{chrM_fraction}\\n\")\n",
        "\n",
        "print(f\"\\n‚úì Results saved to: {chrM_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "790ee298",
      "metadata": {},
      "source": [
        "## Step 9: Mark Duplicates with Picard\n",
        "\n",
        "**What does this do?** Identifies PCR duplicate reads (same start/end position).\n",
        "\n",
        "**üìù TODO: Run Picard MarkDuplicates.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0d25323",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 5: Mark duplicate reads\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "filtered_bam = os.path.join(OUTPUT_DIR, f\"{basename}_filtered.bam\")\n",
        "sorted_filtered_bam = os.path.join(OUTPUT_DIR, f\"{basename}_sorted_filtered.bam\")\n",
        "mkdup_bam = os.path.join(OUTPUT_DIR, f\"{basename}_mkdup.bam\")\n",
        "dup_metrics = os.path.join(picard_dir, f\"{basename}_dup_metrics.txt\")\n",
        "\n",
        "print(\"[1/2] Sorting filtered BAM...\")\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{samtools_container}\",\n",
        "    \"samtools\", \"sort\",\n",
        "    \"-@\", str(threads),\n",
        "    \"-o\", sorted_filtered_bam,\n",
        "    filtered_bam\n",
        "]\n",
        "subprocess.run(cmd, capture_output=False)\n",
        "print(\"‚úì Sorting done\")\n",
        "\n",
        "print(\"[2/2] Marking duplicates with Picard...\")\n",
        "# TODO: Complete the Picard command\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{picard_container}\",  # TODO: Which container?\n",
        "    \"picard\", \"MarkDuplicates\",\n",
        "    \"-I\", sorted_filtered_bam,\n",
        "    \"-O\", mkdup_bam,\n",
        "    \"-M\", dup_metrics,\n",
        "    \"-REMOVE_DUPLICATES\", \"false\",  # Mark but don't remove yet\n",
        "    \"-ASSUME_SORT_ORDER\", \"coordinate\"\n",
        "]\n",
        "\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"‚úì Duplicate marking completed!\")\n",
        "    print(f\"  Marked BAM: {mkdup_bam}\")\n",
        "    print(f\"  Metrics: {dup_metrics}\")\n",
        "    \n",
        "    # Show duplicate rate\n",
        "    with open(dup_metrics, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith(\"LIBRARY\"):\n",
        "                next_line = next(f)\n",
        "                fields = next_line.strip().split('\\t')\n",
        "                if len(fields) > 8:\n",
        "                    dup_rate = float(fields[8])\n",
        "                    print(f\"\\n  Duplicate rate: {dup_rate*100:.2f}%\")\n",
        "                break\n",
        "else:\n",
        "    print(f\"‚úó Error: {result.stderr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b836ce28",
      "metadata": {},
      "source": [
        "## Step 10: Calculate Library Complexity (PBC1, PBC2, NRF)\n",
        "\n",
        "**What does this do?** Measures library quality and diversity.\n",
        "\n",
        "**Quality Thresholds:**\n",
        "- **NRF** > 0.9: Excellent, > 0.8: Good, < 0.5: Poor\n",
        "- **PBC1** > 0.9: Excellent, > 0.7: Good, < 0.5: Poor  \n",
        "- **PBC2** > 10: Excellent, > 3: Good, < 1: Poor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85d36977",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 6: Calculate library complexity metrics\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "mkdup_bam = os.path.join(OUTPUT_DIR, f\"{basename}_mkdup.bam\")\n",
        "qc_file = os.path.join(qc_dir, f\"{basename}_qc.txt\")\n",
        "\n",
        "print(\"Calculating PBC1, PBC2, and NRF...\")\n",
        "print(\"(This may take a few minutes)\")\n",
        "\n",
        "# Sort by query name for complexity calculation\n",
        "name_sorted_bam = os.path.join(OUTPUT_DIR, f\"{basename}_nsorted_tmp.bam\")\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{samtools_container}\",\n",
        "    \"samtools\", \"sort\", \"-n\",\n",
        "    \"-@\", str(threads),\n",
        "    \"-o\", name_sorted_bam,\n",
        "    mkdup_bam\n",
        "]\n",
        "subprocess.run(cmd, capture_output=False)\n",
        "\n",
        "# Calculate metrics using bedtools\n",
        "cmd = f\"\"\"\n",
        "singularity exec -e --no-home --bind {BIND_DIR}:{BIND_DIR} docker://{bedtools_container} \\\n",
        "bedtools bamtobed -bedpe -i {name_sorted_bam} | \\\n",
        "awk 'BEGIN{{OFS=\"\\\\t\"}}{{print $1,$2,$4,$6,$9,$10}}' | \\\n",
        "sort | uniq -c | \\\n",
        "awk 'BEGIN{{mt=0;m0=0;m1=0;m2=0}}\n",
        "     ($1==1){{m1=m1+1}} \n",
        "     ($1==2){{m2=m2+1}} \n",
        "     {{m0=m0+1}} \n",
        "     {{mt=mt+$1}} \n",
        "     END{{printf \"%d\\\\t%d\\\\t%d\\\\t%d\\\\t%f\\\\t%f\\\\t%f\\\\n\", mt,m0,m1,m2,m0/mt,m1/m0,m1/m2}}'\n",
        "\"\"\"\n",
        "\n",
        "result = subprocess.run(cmd, shell=True, capture_output=False, text=True)\n",
        "metrics = result.stdout.strip()\n",
        "\n",
        "# Parse and display results\n",
        "values = metrics.split('\\t')\n",
        "if len(values) == 7:\n",
        "    total_reads = int(values[0])\n",
        "    distinct_loci = int(values[1])\n",
        "    one_read_loci = int(values[2])\n",
        "    two_read_loci = int(values[3])\n",
        "    NRF = float(values[4])\n",
        "    PBC1 = float(values[5])\n",
        "    PBC2 = float(values[6])\n",
        "    \n",
        "    print(f\"\\nüìä Library Complexity Metrics:\")\n",
        "    print(f\"  Total reads: {total_reads:,}\")\n",
        "    print(f\"  Distinct loci: {distinct_loci:,}\")\n",
        "    print(f\"  NRF (Non-Redundant Fraction): {NRF:.4f}\")\n",
        "    print(f\"  PBC1 (Bottlenecking Coefficient 1): {PBC1:.4f}\")\n",
        "    print(f\"  PBC2 (Bottlenecking Coefficient 2): {PBC2:.4f}\")\n",
        "    \n",
        "    # Quality assessment\n",
        "    print(f\"\\n  Quality Assessment:\")\n",
        "    print(f\"    NRF: {'‚úì Excellent' if NRF > 0.9 else '‚úì Good' if NRF > 0.8 else '‚ö† Moderate' if NRF > 0.5 else '‚úó Poor'}\")\n",
        "    print(f\"    PBC1: {'‚úì Excellent' if PBC1 > 0.9 else '‚úì Good' if PBC1 > 0.7 else '‚ö† Moderate' if PBC1 > 0.5 else '‚úó Poor'}\")\n",
        "    print(f\"    PBC2: {'‚úì Excellent' if PBC2 > 10 else '‚úì Good' if PBC2 > 3 else '‚ö† Moderate' if PBC2 > 1 else '‚úó Poor'}\")\n",
        "    \n",
        "    # Save to file\n",
        "    with open(qc_file, 'w') as f:\n",
        "        f.write(\"Total_reads\\tDistinct_loci\\tOne_read_loci\\tTwo_read_loci\\tNRF\\tPBC1\\tPBC2\\n\")\n",
        "        f.write(metrics + \"\\n\")\n",
        "    \n",
        "    print(f\"\\n‚úì Results saved to: {qc_file}\")\n",
        "\n",
        "# Clean up temporary file\n",
        "os.remove(name_sorted_bam)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "267fcd4f",
      "metadata": {},
      "source": [
        "## Step 11: Filter Low Quality Reads and Remove Duplicates\n",
        "\n",
        "**What does this do?** Removes duplicates and low-quality alignments (MAPQ < 10).\n",
        "\n",
        "**üìù TODO: Apply final filters.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e37e60b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 7: Filter low quality reads and duplicates\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "mkdup_bam = os.path.join(OUTPUT_DIR, f\"{basename}_mkdup.bam\")\n",
        "final_bam = os.path.join(OUTPUT_DIR, f\"{basename}_final.bam\")\n",
        "\n",
        "print(\"Filtering reads with MAPQ < 10 and removing duplicates...\")\n",
        "\n",
        "# TODO: Complete the samtools filter command\n",
        "# Hint: -F 1024 removes duplicates, -q 10 filters by quality\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{samtools_container}\",\n",
        "    \"samtools\", \"view\",\n",
        "    \"-@\", str(threads),\n",
        "    \"-F\", \"1024\",     # Remove duplicate flag\n",
        "    \"-q\", \"10\",       # Minimum MAPQ quality\n",
        "    \"-b\",             # Output BAM\n",
        "    \"-o\", final_bam,\n",
        "    mkdup_bam\n",
        "]\n",
        "\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    # Sort and index\n",
        "    print(\"Sorting and indexing final BAM...\")\n",
        "    sorted_final = final_bam.replace('.bam', '_sorted.bam')\n",
        "    cmd = [\n",
        "        \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "        \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "        f\"docker://{samtools_container}\",\n",
        "        \"samtools\", \"sort\",\n",
        "        \"-@\", str(threads),\n",
        "        \"-o\", sorted_final,\n",
        "        final_bam\n",
        "    ]\n",
        "    subprocess.run(cmd, capture_output=False)\n",
        "    os.replace(sorted_final, final_bam)\n",
        "    \n",
        "    # Index\n",
        "    cmd = [\n",
        "        \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "        \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "        f\"docker://{samtools_container}\",\n",
        "        \"samtools\", \"index\",\n",
        "        \"-@\", str(threads),\n",
        "        final_bam\n",
        "    ]\n",
        "    subprocess.run(cmd, capture_output=False)\n",
        "    \n",
        "    print(\"‚úì Filtering completed!\")\n",
        "    print(f\"  Final BAM: {final_bam}\")\n",
        "else:\n",
        "    print(f\"‚úó Error: {result.stderr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca137fd",
      "metadata": {},
      "source": [
        "## Step 12: ATAC-seq Specific Read Shifting\n",
        "\n",
        "**What does this do?** Shifts reads to represent the center of transposon binding (+4bp for forward, -5bp for reverse).\n",
        "\n",
        "This is **specific to ATAC-seq** and improves peak resolution!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba6b4a1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 8: ATAC-seq read shifting\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "final_bam = os.path.join(OUTPUT_DIR, f\"{basename}_final.bam\")\n",
        "shifted_bam = os.path.join(OUTPUT_DIR, f\"{basename}_final_shifted.bam\")\n",
        "\n",
        "print(\"Shifting reads for ATAC-seq (adjusting for Tn5 binding)...\")\n",
        "print(\"Forward strand: +4bp, Reverse strand: -5bp\")\n",
        "\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{deeptools_container}\",\n",
        "    \"alignmentSieve\",\n",
        "    \"--ATACshift\",    # Special ATAC-seq shift mode\n",
        "    \"-b\", final_bam,\n",
        "    \"-o\", shifted_bam\n",
        "]\n",
        "\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"‚úì Read shifting completed!\")\n",
        "    print(f\"  Shifted BAM: {shifted_bam}\")\n",
        "else:\n",
        "    print(f\"‚úó Error: {result.stderr}\")\n",
        "    \n",
        "# Question: Why do we shift reads in ATAC-seq analysis?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae31f3ee",
      "metadata": {},
      "source": [
        "## Step 13: Call Peaks with MACS2\n",
        "\n",
        "**What does this do?** Identifies regions of open chromatin (peaks).\n",
        "\n",
        "**üìù TODO: Run MACS2 peak calling.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3fe9f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 9: Peak calling with MACS2\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "final_bam = os.path.join(OUTPUT_DIR, f\"{basename}_final.bam\")\n",
        "\n",
        "print(\"Calling peaks with MACS2...\")\n",
        "\n",
        "# TODO: Complete the MACS2 command\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{macs2_container}\",  # TODO: Which container?\n",
        "    \"macs2\", \"callpeak\",\n",
        "    \"-f\", \"BAMPE\",           # Paired-end BAM format\n",
        "    \"-g\", \"hs\",              # Human genome size\n",
        "    \"--keep-dup\", \"all\",     # Keep all reads (already filtered)\n",
        "    \"-n\", basename,\n",
        "    \"-t\", final_bam,\n",
        "    \"--outdir\", peaks_dir\n",
        "]\n",
        "\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"‚úì Peak calling completed!\")\n",
        "    \n",
        "    # Count peaks\n",
        "    peak_file = os.path.join(peaks_dir, f\"{basename}_peaks.narrowPeak\")\n",
        "    with open(peak_file, 'r') as f:\n",
        "        num_peaks = sum(1 for line in f)\n",
        "    \n",
        "    print(f\"\\n  üìä Results:\")\n",
        "    print(f\"    Peaks identified: {num_peaks:,}\")\n",
        "    print(f\"    Peak file: {peak_file}\")\n",
        "    print(f\"    Summit file: {os.path.join(peaks_dir, f'{basename}_summits.bed')}\")\n",
        "    \n",
        "    # Show first few peaks\n",
        "    print(f\"\\n  Preview of peaks:\")\n",
        "    with open(peak_file, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i < 5:\n",
        "                fields = line.strip().split('\\t')\n",
        "                print(f\"    {fields[0]}:{fields[1]}-{fields[2]} (score: {fields[6]})\")\n",
        "            else:\n",
        "                break\n",
        "else:\n",
        "    print(f\"‚úó Error: {result.stderr}\")\n",
        "    \n",
        "# Question: What does the peak score represent?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fbccdc1",
      "metadata": {},
      "source": [
        "## Step 14: Calculate FRiP Score (Fraction of Reads in Peaks)\n",
        "\n",
        "**What does this do?** Measures signal-to-noise ratio.\n",
        "\n",
        "**Quality Thresholds:**\n",
        "- **FRiP** > 0.3: Excellent\n",
        "- **FRiP** > 0.2: Good\n",
        "- **FRiP** < 0.1: Poor (failed experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87f02d84",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 10: Calculate FRiP score\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "final_bam = os.path.join(OUTPUT_DIR, f\"{basename}_final.bam\")\n",
        "peak_file = os.path.join(peaks_dir, f\"{basename}_peaks.narrowPeak\")\n",
        "\n",
        "print(\"Calculating Fraction of Reads in Peaks (FRiP)...\")\n",
        "\n",
        "# Count total reads\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{samtools_container}\",\n",
        "    \"samtools\", \"view\", \"-c\", final_bam\n",
        "]\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "total_reads = int(result.stdout.strip())\n",
        "\n",
        "# Count reads in peaks using bedtools\n",
        "cmd = f\"\"\"\n",
        "singularity exec -e --no-home --bind {BIND_DIR}:{BIND_DIR} docker://{bedtools_container} \\\n",
        "bedtools sort -i {peak_file} | \\\n",
        "singularity exec -e --no-home --bind {BIND_DIR}:{BIND_DIR} docker://{bedtools_container} \\\n",
        "bedtools merge -i stdin | \\\n",
        "singularity exec -e --no-home --bind {BIND_DIR}:{BIND_DIR} docker://{bedtools_container} \\\n",
        "bedtools intersect -u -nonamecheck -a {final_bam} -b stdin -ubam | \\\n",
        "singularity exec -e --no-home --bind {BIND_DIR}:{BIND_DIR} docker://{samtools_container} \\\n",
        "samtools view -c\n",
        "\"\"\"\n",
        "\n",
        "result = subprocess.run(cmd, shell=True, capture_output=False, text=True)\n",
        "reads_in_peaks = int(result.stdout.strip())\n",
        "\n",
        "# Calculate FRiP\n",
        "FRiP = reads_in_peaks / total_reads if total_reads > 0 else 0\n",
        "\n",
        "print(f\"\\nüìä FRiP Score:\")\n",
        "print(f\"  Total reads: {total_reads:,}\")\n",
        "print(f\"  Reads in peaks: {reads_in_peaks:,}\")\n",
        "print(f\"  FRiP score: {FRiP:.4f} ({FRiP*100:.2f}%)\")\n",
        "\n",
        "if FRiP > 0.3:\n",
        "    print(\"  ‚úì Excellent quality (>30%)\")\n",
        "elif FRiP > 0.2:\n",
        "    print(\"  ‚úì Good quality (20-30%)\")\n",
        "elif FRiP > 0.1:\n",
        "    print(\"  ‚ö† Moderate quality (10-20%)\")\n",
        "else:\n",
        "    print(\"  ‚úó Poor quality (<10%) - experiment may have failed\")\n",
        "\n",
        "# Append to QC file\n",
        "qc_file = os.path.join(qc_dir, f\"{basename}_qc.txt\")\n",
        "with open(qc_file, 'a') as f:\n",
        "    f.write(f\"\\nFRiP:\\n{FRiP}\\n\")\n",
        "\n",
        "print(f\"\\n‚úì FRiP score saved to: {qc_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a89bc29b",
      "metadata": {},
      "source": [
        "## Step 15: Create BigWig Coverage Track\n",
        "\n",
        "**What does this do?** Creates a normalized genome browser track for visualization.\n",
        "\n",
        "**üìù TODO: Generate coverage track.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7897ea3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 11: Generate BigWig coverage track\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "final_bam = os.path.join(OUTPUT_DIR, f\"{basename}_final.bam\")\n",
        "bigwig_file = os.path.join(OUTPUT_DIR, f\"{basename}_final_RPKM_Norm_bs10.bw\")\n",
        "\n",
        "print(\"Creating normalized coverage track (RPKM normalized)...\")\n",
        "\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{deeptools_container}\",\n",
        "    \"bamCoverage\",\n",
        "    \"-b\", final_bam,\n",
        "    \"-o\", bigwig_file,\n",
        "    \"-bs\", \"10\",              # 10bp bins\n",
        "    \"--normalizeUsing\", \"RPKM\",\n",
        "    \"-p\", str(threads)\n",
        "]\n",
        "\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"‚úì BigWig file created!\")\n",
        "    print(f\"  File: {bigwig_file}\")\n",
        "    print(f\"\\n  üí° This file can be loaded into genome browsers like:\")\n",
        "    print(f\"     - IGV (Integrative Genomics Viewer)\")\n",
        "    print(f\"     - UCSC Genome Browser\")\n",
        "else:\n",
        "    print(f\"‚úó Error: {result.stderr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b50ae9c8",
      "metadata": {},
      "source": [
        "## Step 16: Remove Blacklisted Regions from Peaks\n",
        "\n",
        "**What does this do?** Removes peaks in problematic genomic regions (artifacts, repetitive DNA).\n",
        "\n",
        "**üìù TODO: Filter peaks using the ENCODE blacklist.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ce289ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 12: Remove blacklisted regions from peaks\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "peak_file = os.path.join(peaks_dir, f\"{basename}_peaks.narrowPeak\")\n",
        "summit_file = os.path.join(peaks_dir, f\"{basename}_summits.bed\")\n",
        "filtered_peaks = os.path.join(peaks_dir, f\"{basename}_peaks_blacklist_filtered.narrowPeak\")\n",
        "filtered_summits = os.path.join(peaks_dir, f\"{basename}_summits_blacklist_filtered.bed\")\n",
        "\n",
        "print(\"Removing peaks overlapping ENCODE blacklist regions...\")\n",
        "\n",
        "# Filter peaks\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{bedtools_container}\",\n",
        "    \"bedtools\", \"subtract\",\n",
        "    \"-A\",              # Remove entire peak if any overlap\n",
        "    \"-a\", peak_file,\n",
        "    \"-b\", BLACKLIST\n",
        "]\n",
        "\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "with open(filtered_peaks, 'w') as f:\n",
        "    f.write(result.stdout)\n",
        "\n",
        "# Filter summits\n",
        "cmd = [\n",
        "    \"singularity\", \"exec\", \"-e\", \"--no-home\",\n",
        "    \"--bind\", f\"{BIND_DIR}:{BIND_DIR}\",\n",
        "    f\"docker://{bedtools_container}\",\n",
        "    \"bedtools\", \"subtract\",\n",
        "    \"-A\",\n",
        "    \"-a\", summit_file,\n",
        "    \"-b\", BLACKLIST\n",
        "]\n",
        "\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "with open(filtered_summits, 'w') as f:\n",
        "    f.write(result.stdout)\n",
        "\n",
        "# Count filtered peaks\n",
        "with open(filtered_peaks, 'r') as f:\n",
        "    num_filtered_peaks = sum(1 for line in f)\n",
        "\n",
        "with open(peak_file, 'r') as f:\n",
        "    num_original_peaks = sum(1 for line in f)\n",
        "\n",
        "removed_peaks = num_original_peaks - num_filtered_peaks\n",
        "\n",
        "print(f\"\\n‚úì Blacklist filtering completed!\")\n",
        "print(f\"  Original peaks: {num_original_peaks:,}\")\n",
        "print(f\"  Filtered peaks: {num_filtered_peaks:,}\")\n",
        "print(f\"  Removed peaks: {removed_peaks:,} ({removed_peaks/num_original_peaks*100:.1f}%)\")\n",
        "print(f\"\\n  Final peak file: {filtered_peaks}\")\n",
        "print(f\"  Final summit file: {filtered_summits}\")\n",
        "\n",
        "# Question: Why do we need to remove blacklisted regions?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8121b96",
      "metadata": {},
      "source": [
        "## Step 17: Pipeline Summary and Quality Assessment\n",
        "\n",
        "**Congratulations!** üéâ You've completed the ATAC-seq pipeline!\n",
        "\n",
        "Let's review all quality metrics to assess your experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4e95d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"ATAC-SEQ PIPELINE COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\n‚úì Sample processed: {basename}\")\n",
        "print(f\"‚úì Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"QUALITY METRICS SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Read chrM fraction\n",
        "chrM_file = os.path.join(qc_dir, f\"{basename}_chrM_fraction.txt\")\n",
        "if os.path.exists(chrM_file):\n",
        "    with open(chrM_file, 'r') as f:\n",
        "        next(f)  # Skip header\n",
        "        line = f.readline().strip().split('\\t')\n",
        "        chrM_frac = float(line[2])\n",
        "        print(f\"\\n1. Mitochondrial Reads: {chrM_frac*100:.2f}%\")\n",
        "        print(f\"   {'‚úì PASS' if chrM_frac < 0.1 else '‚ö† WARNING' if chrM_frac < 0.2 else '‚úó FAIL'}\")\n",
        "\n",
        "# Read library complexity\n",
        "qc_file = os.path.join(qc_dir, f\"{basename}_qc.txt\")\n",
        "if os.path.exists(qc_file):\n",
        "    with open(qc_file, 'r') as f:\n",
        "        header = f.readline()\n",
        "        if 'NRF' in header:\n",
        "            values = f.readline().strip().split('\\t')\n",
        "            NRF = float(values[4])\n",
        "            PBC1 = float(values[5])\n",
        "            PBC2 = float(values[6])\n",
        "            \n",
        "            print(f\"\\n2. Library Complexity:\")\n",
        "            print(f\"   NRF: {NRF:.4f} {'‚úì Excellent' if NRF > 0.9 else '‚úì Good' if NRF > 0.8 else '‚ö† Moderate' if NRF > 0.5 else '‚úó Poor'}\")\n",
        "            print(f\"   PBC1: {PBC1:.4f} {'‚úì Excellent' if PBC1 > 0.9 else '‚úì Good' if PBC1 > 0.7 else '‚ö† Moderate' if PBC1 > 0.5 else '‚úó Poor'}\")\n",
        "            print(f\"   PBC2: {PBC2:.4f} {'‚úì Excellent' if PBC2 > 10 else '‚úì Good' if PBC2 > 3 else '‚ö† Moderate' if PBC2 > 1 else '‚úó Poor'}\")\n",
        "        \n",
        "        # Read FRiP\n",
        "        for line in f:\n",
        "            if 'FRiP' in line:\n",
        "                frip_line = f.readline().strip()\n",
        "                if frip_line:\n",
        "                    FRiP = float(frip_line)\n",
        "                    print(f\"\\n3. Signal-to-Noise (FRiP): {FRiP:.4f} ({FRiP*100:.2f}%)\")\n",
        "                    print(f\"   {'‚úì Excellent' if FRiP > 0.3 else '‚úì Good' if FRiP > 0.2 else '‚ö† Moderate' if FRiP > 0.1 else '‚úó Poor'}\")\n",
        "\n",
        "# Peak counts\n",
        "filtered_peaks = os.path.join(peaks_dir, f\"{basename}_peaks_blacklist_filtered.narrowPeak\")\n",
        "if os.path.exists(filtered_peaks):\n",
        "    with open(filtered_peaks, 'r') as f:\n",
        "        num_peaks = sum(1 for line in f)\n",
        "    print(f\"\\n4. Peaks Called: {num_peaks:,}\")\n",
        "    print(f\"   {'‚úì PASS' if num_peaks > 10000 else '‚ö† Low peak count'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"OUTPUT FILES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\nüìÅ Main Results Directory: {OUTPUT_DIR}\")\n",
        "print(f\"\\n  Key Files:\")\n",
        "print(f\"  ‚îú‚îÄ {basename}_final.bam              ‚Üê Final aligned reads\")\n",
        "print(f\"  ‚îú‚îÄ {basename}_final_RPKM_Norm_bs10.bw ‚Üê Coverage track (load in IGV)\")\n",
        "print(f\"  ‚îú‚îÄ {basename}_peaks/\")\n",
        "print(f\"  ‚îÇ  ‚îú‚îÄ {basename}_peaks_blacklist_filtered.narrowPeak  ‚Üê Final peaks\")\n",
        "print(f\"  ‚îÇ  ‚îî‚îÄ {basename}_summits_blacklist_filtered.bed       ‚Üê Peak summits\")\n",
        "print(f\"  ‚îî‚îÄ {basename}_qc/\")\n",
        "print(f\"     ‚îú‚îÄ {basename}_qc.txt              ‚Üê All QC metrics\")\n",
        "print(f\"     ‚îî‚îÄ {basename}_chrM_fraction.txt   ‚Üê Mitochondrial fraction\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"NEXT STEPS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n1. üìä Visualize your data:\")\n",
        "print(\"   - Load BigWig file into IGV or UCSC Genome Browser\")\n",
        "print(\"   - Examine peak locations relative to genes\")\n",
        "\n",
        "print(\"\\n2. üîç Downstream analysis:\")\n",
        "print(\"   - Motif enrichment analysis (HOMER, MEME)\")\n",
        "print(\"   - Differential accessibility (DiffBind, DESeq2)\")\n",
        "print(\"   - Footprinting analysis (TOBIAS, HINT)\")\n",
        "print(\"   - Peak annotation (ChIPseeker, GREAT)\")\n",
        "\n",
        "print(\"\\n3. üìù Review questions:\")\n",
        "print(\"   - What percentage of your genome is accessible?\")\n",
        "print(\"   - Are peaks enriched at promoters or enhancers?\")\n",
        "print(\"   - What transcription factors might be active?\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Well done! You've successfully processed ATAC-seq data! üéâ\")\n",
        "print(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
